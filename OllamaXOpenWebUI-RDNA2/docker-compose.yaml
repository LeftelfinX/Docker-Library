networks:
  AI_network:
    name: AI_network
    driver: bridge

services:
  # Ollama Runtime
  ollama:
    image: ollama/ollama:rocm
    container_name: ollama-container
    restart: always
    devices:
      - /dev/kfd
      - /dev/dri
    environment:
      - HSA_OVERRIDE_GFX_VERSION=10.3.0
      - HCC_AMDGPU_TARGET=gfx1030
    volumes:
      - ${HOME}/.Docker-Volumes/ollama_data:/root/.ollama
    networks:
      - AI_network
    ports:
      - "127.0.0.1:11434:11434"
    labels:
      - "com.centurylinklabs.watchtower.enable=true"

  # Open WebUI
  open-webui:
    image: ghcr.io/open-webui/open-webui:latest
    container_name: open-webui
    restart: always
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
    volumes:
      - ${HOME}/.Docker-Volumes/open-webui:/app/backend/data
    networks:
      - AI_network
    ports:
      - "6500:8080"
    labels:
      - "com.centurylinklabs.watchtower.enable=true"

volumes:
  ollama:
  open-webui:
